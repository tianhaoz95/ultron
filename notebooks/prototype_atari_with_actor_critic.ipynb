{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of prototype_atari_with_actor_critic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c9558bb2cb1943fca94827c2f996898d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_040a3e11db2b46938710e79e325e7680",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a2f803395dc24daf825dd74aff5a8b66",
              "IPY_MODEL_1723d9db3f0441eca4457fcdbaee0207"
            ]
          }
        },
        "040a3e11db2b46938710e79e325e7680": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a2f803395dc24daf825dd74aff5a8b66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d8792e87886b447aa67d943e44244920",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 200,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7de716d21575465bbeb70b718d1d12de"
          }
        },
        "1723d9db3f0441eca4457fcdbaee0207": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2d8b8b41ba7e4a9eada27f93e10a85d5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/200 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c55b05732d174b8f9a7d658e6cf5c24c"
          }
        },
        "d8792e87886b447aa67d943e44244920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7de716d21575465bbeb70b718d1d12de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2d8b8b41ba7e4a9eada27f93e10a85d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c55b05732d174b8f9a7d658e6cf5c24c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1ed449042f1742d0856089781d37d854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f51dba57bfb84aceadd987ff0d321671",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_18b18b9b20ab415f98f0679683291318",
              "IPY_MODEL_40e4f959ae4243d8944f736c0090ceac"
            ]
          }
        },
        "f51dba57bfb84aceadd987ff0d321671": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "18b18b9b20ab415f98f0679683291318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_912baadc8a044b38a8d9cbbb22fa41b9",
            "_dom_classes": [],
            "description": "starting 40 workers: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 40,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 40,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b2612ffdf30946f68a4af899299cbf6b"
          }
        },
        "40e4f959ae4243d8944f736c0090ceac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_85ece9a82faf4ebb85a5e4dd8a165ab2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 40/40 [00:08&lt;00:00,  4.91it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c98dbb9c32b4b6995b5a507c69b0308"
          }
        },
        "912baadc8a044b38a8d9cbbb22fa41b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b2612ffdf30946f68a4af899299cbf6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "85ece9a82faf4ebb85a5e4dd8a165ab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c98dbb9c32b4b6995b5a507c69b0308": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tianhaoz95/ultron/blob/dev%2Ftry-atari-game/notebooks/prototype_atari_with_actor_critic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DX_OfbY42iKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gym pyvirtualdisplay tqdm > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg x11-utils > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM66lPmrmUx1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get update > /dev/null 2>&1\n",
        "!apt-get install cmake > /dev/null 2>&1\n",
        "!pip install gym[atari] > /dev/null 2>&1\n",
        "!pip install gputil > /dev/null 2>&1\n",
        "!pip install pyglet==1.2.4 > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxSzy33ETUiX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "de6ff13a-188c-4588-8b4a-04538fb9cef4"
      },
      "source": [
        "import tensorflow as tf\n",
        "import GPUtil\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "except ValueError:\n",
        "  try:\n",
        "    print('ERROR: Not connected to a TPU runtime!')\n",
        "    GPUs = GPUtil.getGPUs()\n",
        "    print('GPU count: ' + str(len(GPUs)))\n",
        "    gpu_info = !nvidia-smi\n",
        "    gpu_info = '\\n'.join(gpu_info)\n",
        "    if gpu_info.find('failed') >= 0:\n",
        "      print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "      print('and then re-execute this cell.')\n",
        "    else:\n",
        "      print(gpu_info)\n",
        "  except:\n",
        "    print('Using CPU')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.2.0\n",
            "Running on TPU  ['10.125.197.178:8470']\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.125.197.178:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.125.197.178:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StODOp9qm7As",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ae4fba62-642b-4c64-bf77-1616e4db6bb0"
      },
      "source": [
        "import gym\n",
        "import threading\n",
        "import math\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "import multiprocessing\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from gym.wrappers import Monitor\n",
        "from tensorflow import keras\n",
        "from os import path\n",
        "from time import sleep\n",
        "from tqdm.notebook import tqdm\n",
        "from IPython.display import HTML\n",
        "from IPython import display as ipythondisplay\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Display cmd_param=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1001'] cmd=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1001'] oserror=None return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvT2J4Oa6AsX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28e59f8f-80c1-47ef-ef34-c7cdf941c40c"
      },
      "source": [
        "print('using tensorflow', tf.__version__)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using tensorflow 2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR4rdPq23olN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")\n",
        "\n",
        "def wrap_env(env):\n",
        "  wrapped_env = Monitor(env, './video', force=True)\n",
        "  return wrapped_env"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG-mqsx41fhc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PipelineArgs():\n",
        "  def __init__(self,\n",
        "               game_name='Acrobot-v1',\n",
        "               mode='train',\n",
        "               max_eps=100,\n",
        "               update_freq=20,\n",
        "               gamma=0.99,\n",
        "               model_path='.',\n",
        "               load_model=False,\n",
        "               max_testing_steps=1000,\n",
        "               lr=0.001):\n",
        "    self.game_name = game_name\n",
        "    self.mode = mode\n",
        "    self.gamma = gamma\n",
        "    self.update_freq = update_freq\n",
        "    self.lr = lr\n",
        "    self.max_eps = max_eps\n",
        "    self.load_model = load_model\n",
        "    self.model_path = model_path\n",
        "    self.max_testing_steps = max_testing_steps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bz8PHZKXb-db",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class History():\n",
        "  def __init__(self, args):\n",
        "    self.history = pd.DataFrame()\n",
        "    self.args = args\n",
        "  \n",
        "  def record(self, eps_reward):\n",
        "    self.eps_rewards.append(eps_reward)\n",
        "\n",
        "  def save(self):\n",
        "    self.history['eps_rewards'] = self.eps_rewards\n",
        "    self.history.to_csv(path.join(self.args.model_path, 'history.csv'))\n",
        "  \n",
        "  def load(self):\n",
        "    if path.exists(\n",
        "        path.join(\n",
        "            self.args.model_path, 'history.csv')) and self.args.load_model:\n",
        "      self.history = pd.DataFrame()\n",
        "      self.history.read_csv(path.join(self.args.model_path, 'history.csv'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "to5WdjMOBij4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Memory():\n",
        "  def __init__(self):\n",
        "    self.states = []\n",
        "    self.actions = []\n",
        "    self.rewards = []\n",
        "  \n",
        "  def store(self, state, action, reward):\n",
        "    self.states.append(state)\n",
        "    self.actions.append(action)\n",
        "    self.rewards.append(reward)\n",
        "\n",
        "  def clear(self):\n",
        "    self.states = []\n",
        "    self.actions = []\n",
        "    self.rewards = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPNOZzhineIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Worker(threading.Thread):\n",
        "  # The cumulative episode played\n",
        "  global_eps = 0\n",
        "  best_score = 0\n",
        "  lock = threading.Lock()\n",
        "\n",
        "  def __init__(self,\n",
        "               args,\n",
        "               action_size,\n",
        "               state_size,\n",
        "               global_model,\n",
        "               opt,\n",
        "               pbar,\n",
        "               callback):\n",
        "    super(Worker, self).__init__()\n",
        "    self.args = args\n",
        "    self.game_name = self.args.game_name\n",
        "    self.env = gym.make(self.game_name)\n",
        "    self.action_size = action_size\n",
        "    self.state_size = state_size\n",
        "    self.local_model = ActorCriticModel(self.state_size, self.action_size)\n",
        "    self.eps_loss = 0\n",
        "    self.opt = opt\n",
        "    self.global_model = global_model\n",
        "    self.pbar = pbar\n",
        "    self.callback = callback\n",
        "\n",
        "  def compute_loss(self, done, new_state, memory):\n",
        "    if done:\n",
        "      reward_sum = 0\n",
        "    else:\n",
        "      reward_sum = self.local_model(\n",
        "          tf.convert_to_tensor(\n",
        "              new_state[None, :],\n",
        "              dtype=tf.float32))[-1].numpy()[0]\n",
        "    discounted_rewards = []\n",
        "    for reward in memory.rewards[::-1]:\n",
        "      reward_sum = reward + self.args.gamma * reward_sum\n",
        "      discounted_rewards.append(reward_sum)\n",
        "    discounted_rewards.reverse()\n",
        "    past_states = np.array(memory.states)\n",
        "    logits, values = self.local_model(\n",
        "        tf.convert_to_tensor(past_states, dtype=tf.float32))\n",
        "    advantage = tf.convert_to_tensor(\n",
        "        np.array(discounted_rewards)[:, None], dtype=tf.float32) - values\n",
        "    # Calculate the loss for value function which mean how off is our\n",
        "    # predicted value from the true value estimated from the discounted\n",
        "    # reward.\n",
        "    value_loss = advantage ** 2\n",
        "    # Calculate the policy loss\n",
        "    policy = tf.nn.softmax(logits)\n",
        "    entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
        "        labels=policy, logits=logits)\n",
        "    policy_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "        labels=memory.actions, logits=logits)\n",
        "    policy_loss *= tf.stop_gradient(advantage)\n",
        "    policy_loss -= 0.01 * entropy\n",
        "    # Combine the value and policy loss to be a single trainable\n",
        "    total_loss = tf.reduce_mean((0.5 * value_loss + policy_loss))\n",
        "    return total_loss\n",
        "\n",
        "  def compute_and_apply_gradient(self, done, new_state, mem):\n",
        "    with tf.GradientTape() as tape:\n",
        "      total_loss = self.compute_loss(done, new_state, mem)\n",
        "    self.eps_loss += total_loss\n",
        "    grads = tape.gradient(\n",
        "        total_loss, self.local_model.trainable_weights)\n",
        "    self.opt.apply_gradients(zip(\n",
        "        grads, self.global_model.trainable_weights))\n",
        "    self.local_model.set_weights(self.global_model.get_weights())\n",
        "\n",
        "  def run(self):\n",
        "    # Prepare variables\n",
        "    mem = Memory()\n",
        "    total_steps = 1\n",
        "    # Check the maximum episode of learning is reached\n",
        "    while Worker.global_eps < self.args.max_eps:\n",
        "      current_state = self.env.reset()\n",
        "      mem.clear()\n",
        "      done = False\n",
        "      ep_reward = 0\n",
        "      self.eps_loss = 0\n",
        "      time_count = 0\n",
        "      ep_steps = 0\n",
        "      # Check if the game is over\n",
        "      while not done:\n",
        "        # Get the policy and play the game\n",
        "        logits, _ = self.local_model(\n",
        "            tf.convert_to_tensor(np.array([current_state]), dtype=tf.float32))\n",
        "        probs = tf.nn.softmax(logits)\n",
        "        action = np.random.choice(self.action_size, p=probs.numpy()[0])\n",
        "        new_state, reward, done, info = self.env.step(action)\n",
        "        if not done:\n",
        "          reward -= 1\n",
        "        ep_reward += reward\n",
        "        mem.store(current_state, action, reward)\n",
        "        # If the explore time limit has been reached or\n",
        "        # the game is over, then update the models\n",
        "        if time_count >= self.args.update_freq or done:\n",
        "          self.compute_and_apply_gradient(done, new_state, mem)\n",
        "          mem.clear()\n",
        "          time_count = 0\n",
        "          if done:\n",
        "            with Worker.lock:\n",
        "              if Worker.global_eps == 0:\n",
        "                Worker.best_score = ep_reward\n",
        "              if ep_reward > Worker.best_score:\n",
        "                self.global_model.save_weights(\n",
        "                    path.join(self.args.model_path, 'best.h5'))\n",
        "                Worker.best_score = ep_reward\n",
        "              else:\n",
        "                self.global_model.save_weights(\n",
        "                    path.join(self.args.model_path, 'backup.h5'))\n",
        "              Worker.global_eps += 1\n",
        "              self.pbar.set_description(\n",
        "                  f'step: {ep_steps}, reward {ep_reward}/{Worker.best_score}')\n",
        "              self.pbar.update(1)\n",
        "        ep_steps += 1\n",
        "        time_count += 1\n",
        "        current_state = new_state\n",
        "        total_steps += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnSC4zC4nt9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ActorCriticModel(keras.Model):\n",
        "  def __init__(self, state_size, action_size):\n",
        "    super(ActorCriticModel, self).__init__()\n",
        "    self.state_size = state_size\n",
        "    self.action_size = action_size\n",
        "    self.conv_0 = keras.layers.Conv2D(\n",
        "        filters=4,\n",
        "        activation='relu',\n",
        "        kernel_size=8,\n",
        "        kernel_initializer='random_uniform',\n",
        "        input_shape=(None, 210, 160, 3))\n",
        "    self.conv_1 = keras.layers.Conv2D(\n",
        "        filters=4,\n",
        "        activation='relu',\n",
        "        kernel_initializer='random_uniform',\n",
        "        kernel_size=8)\n",
        "    self.flatten  =keras.layers.Flatten()\n",
        "    self.policy_dense_0 = keras.layers.Dense(\n",
        "        64, kernel_initializer='random_uniform', activation='relu')\n",
        "    self.policy_dense_1 = keras.layers.Dense(\n",
        "        32, kernel_initializer='random_uniform', activation='relu')\n",
        "    self.policy_logits = keras.layers.Dense(self.action_size, activation='relu')\n",
        "    self.value_dense = keras.layers.Dense(\n",
        "        128, kernel_initializer='random_uniform', activation='relu')\n",
        "    self.value = keras.layers.Dense(1)\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    x = self.conv_0(inputs)\n",
        "    x = self.conv_1(x)\n",
        "    x = self.flatten(x)\n",
        "    p = self.policy_dense_0(x)\n",
        "    p = self.policy_dense_1(p)\n",
        "    logits = self.policy_logits(p)\n",
        "    v = self.value_dense(x)\n",
        "    values = self.value(v)\n",
        "    return logits, values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtTON1xmoJCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BaselineModel():\n",
        "  def __init__(self):\n",
        "    print('not implemented')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVDqVpOqn_e0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MasterAgent():\n",
        "  def __init__(self, args):\n",
        "    self.args = args\n",
        "    self.game_name = self.args.game_name\n",
        "    env = gym.make(self.game_name)\n",
        "    self.action_size = env.action_space.n\n",
        "    self.state_size = env.observation_space.shape[0]\n",
        "    self.opt = tf.optimizers.Adam(self.args.lr)\n",
        "    print('state_size: ', self.state_size)\n",
        "    print('action_size: ', self.action_size)\n",
        "    self.global_model = ActorCriticModel(self.state_size, self.action_size)\n",
        "    self.global_model(\n",
        "      tf.convert_to_tensor(\n",
        "      np.random.random((5, 210, 160, 3)),\n",
        "      dtype=tf.float32))\n",
        "    if path.exists(\n",
        "        path.join(self.args.model_path, 'best.h5')) and self.args.load_model:\n",
        "      self.global_model.load_weights(\n",
        "          path.join(self.args.model_path, 'best.h5'))\n",
        "  \n",
        "  def train_sync(self):\n",
        "    pbar = tqdm(total=self.args.max_eps)\n",
        "    worker = Worker(self.args, self.action_size, self.state_size,\n",
        "                    self.global_model, self.opt, pbar, self.eval)\n",
        "    worker.run()\n",
        "    pbar.close()\n",
        "  \n",
        "  def train_async(self):\n",
        "    pbar = tqdm(total=self.args.max_eps)\n",
        "    Worker.global_eps = 0;\n",
        "    workers = [\n",
        "      Worker(self.args, self.action_size, self.state_size,\n",
        "             self.global_model, self.opt, pbar, self.eval)\n",
        "      for i in range(multiprocessing.cpu_count())\n",
        "    ]\n",
        "    worker_pbar = tqdm(total=len(workers))\n",
        "    worker_pbar.set_description(f'starting {len(workers)} workers')\n",
        "    for i, worker in enumerate(workers):\n",
        "      worker.start()\n",
        "      worker_pbar.update(1)\n",
        "    worker_pbar.close()\n",
        "    [w.join() for w in workers]\n",
        "    pbar.close()\n",
        "    self.play()\n",
        "\n",
        "  def eval(self):\n",
        "    print('eval')\n",
        "  \n",
        "  def play(self):\n",
        "    env = wrap_env(gym.make(self.args.game_name))\n",
        "    state = env.reset()\n",
        "    if path.exists(\n",
        "        path.join(self.args.model_path, 'best.h5')):\n",
        "      print('load pre-trained model')\n",
        "      self.global_model.load_weights(\n",
        "          path.join(self.args.model_path, 'best.h5'))\n",
        "    done = False\n",
        "    trial_steps = 0\n",
        "    pbar = tqdm(total=self.args.max_testing_steps)\n",
        "    while (not done) and (trial_steps <= self.args.max_testing_steps):\n",
        "      state_input = tf.convert_to_tensor(state[None, :], dtype=tf.float32)\n",
        "      logit, _ = self.global_model(state_input)\n",
        "      policy = tf.nn.softmax(logit)\n",
        "      action = np.argmax(policy)\n",
        "      state, reward, done, _ = env.step(action)\n",
        "      trial_steps += 1\n",
        "      pbar.update(1)\n",
        "    pbar.close()\n",
        "    env.close()\n",
        "    show_video()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yy5tn0pA2-tB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gym_sanity_check(args):\n",
        "  print('starting gym environment sanity check')\n",
        "  env = wrap_env(gym.make(args.game_name))\n",
        "  inital_observation = env.reset()\n",
        "  sample_action = env.action_space.sample()\n",
        "  print('observation shape: ', np.array(inital_observation).shape)\n",
        "  print('sample action: ', sample_action)\n",
        "  for _ in range(20):\n",
        "    observation = env.reset()\n",
        "    done = False\n",
        "    while not done:\n",
        "        action = env.action_space.sample()\n",
        "        observation, _, done, _ = env.step(action)\n",
        "  env.close()\n",
        "  show_video()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_4XwuN1oFkz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def entry_point(args):\n",
        "  if args.mode == 'sanity':\n",
        "    gym_sanity_check(args)\n",
        "  if args.mode == 'play':\n",
        "    master = MasterAgent(args)\n",
        "    master.play()\n",
        "  if args.mode == 'train_sync':\n",
        "    master = MasterAgent(args)\n",
        "    master.train_sync()\n",
        "  if args.mode == 'train_async':\n",
        "    master = MasterAgent(args)\n",
        "    master.train_async()\n",
        "  print('Hello World')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_oklLOXofGu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132,
          "referenced_widgets": [
            "c9558bb2cb1943fca94827c2f996898d",
            "040a3e11db2b46938710e79e325e7680",
            "a2f803395dc24daf825dd74aff5a8b66",
            "1723d9db3f0441eca4457fcdbaee0207",
            "d8792e87886b447aa67d943e44244920",
            "7de716d21575465bbeb70b718d1d12de",
            "2d8b8b41ba7e4a9eada27f93e10a85d5",
            "c55b05732d174b8f9a7d658e6cf5c24c",
            "1ed449042f1742d0856089781d37d854",
            "f51dba57bfb84aceadd987ff0d321671",
            "18b18b9b20ab415f98f0679683291318",
            "40e4f959ae4243d8944f736c0090ceac",
            "912baadc8a044b38a8d9cbbb22fa41b9",
            "b2612ffdf30946f68a4af899299cbf6b",
            "85ece9a82faf4ebb85a5e4dd8a165ab2",
            "4c98dbb9c32b4b6995b5a507c69b0308"
          ]
        },
        "outputId": "960777b9-23e8-4a86-b8cd-bdf3e705c147"
      },
      "source": [
        "entry_point(\n",
        "    PipelineArgs(\n",
        "        game_name='Berzerk-v0',\n",
        "        update_freq=128,\n",
        "        max_eps=200,\n",
        "        max_testing_steps=2000,\n",
        "        load_model=True,\n",
        "        mode='train_async'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "state_size:  210\n",
            "action_size:  18\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c9558bb2cb1943fca94827c2f996898d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ed449042f1742d0856089781d37d854",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNDSeZ4Nune5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}