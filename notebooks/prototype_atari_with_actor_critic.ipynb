{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of prototype_atari_with_actor_critic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "44f2cb9739db4305ab59e8b7991e8cc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ac353d2b5b324220bfd28b92e825f666",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4a4b2a5354e24fdaaf1eee6eb953034f",
              "IPY_MODEL_5a7dff722ede43b8b5379a22216c7a0f"
            ]
          }
        },
        "ac353d2b5b324220bfd28b92e825f666": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4a4b2a5354e24fdaaf1eee6eb953034f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_95c86602637b4a2b9a69bbb5785278c6",
            "_dom_classes": [],
            "description": "step: 191, reward -2.91/-0.02: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_158e0a7bf5eb4d14a06b10c0abb56c94"
          }
        },
        "5a7dff722ede43b8b5379a22216c7a0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_572bdd2c7e714453a277aed1e4e2c546",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 128/? [09:03&lt;00:00,  1.03s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a4ff58fcaf61472b98238493ca1b31c4"
          }
        },
        "95c86602637b4a2b9a69bbb5785278c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "158e0a7bf5eb4d14a06b10c0abb56c94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "572bdd2c7e714453a277aed1e4e2c546": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a4ff58fcaf61472b98238493ca1b31c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a623ffdf953246f59ee1a12bc14f2055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_053c11c11b594d73b838345a59537871",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dbf6225c053941d9af431451e3c5b711",
              "IPY_MODEL_0029fff1e94c4354bbf2572e99e2bfa2"
            ]
          }
        },
        "053c11c11b594d73b838345a59537871": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dbf6225c053941d9af431451e3c5b711": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cb445b5843cb479f968818ef86309f52",
            "_dom_classes": [],
            "description": "starting 40 workers: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 40,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 40,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f25f94879a8343bb9cbaf2e8e2de5344"
          }
        },
        "0029fff1e94c4354bbf2572e99e2bfa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dda6cf9ab89f4e298b729dd895e3d7d1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 40/40 [00:00&lt;00:00, 1029.92it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e68295094cf64a6e8cbc4c37e09b2fa9"
          }
        },
        "cb445b5843cb479f968818ef86309f52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f25f94879a8343bb9cbaf2e8e2de5344": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dda6cf9ab89f4e298b729dd895e3d7d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e68295094cf64a6e8cbc4c37e09b2fa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tianhaoz95/ultron/blob/dev%2Ftry-atari-game/notebooks/prototype_atari_with_actor_critic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NExKMaqaukJL",
        "colab_type": "code",
        "outputId": "13d4cffd-c25b-41e0-e714-84a251c89e15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DX_OfbY42iKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gym pyvirtualdisplay tqdm > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg x11-utils > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM66lPmrmUx1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get update > /dev/null 2>&1\n",
        "!apt-get install cmake > /dev/null 2>&1\n",
        "!pip install gym[atari] > /dev/null 2>&1\n",
        "!pip install gputil > /dev/null 2>&1\n",
        "!pip install pyglet==1.2.4 > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxSzy33ETUiX",
        "colab_type": "code",
        "outputId": "fb0918e0-0dee-4643-81bc-9e044d9e369e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import GPUtil\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "except ValueError:\n",
        "  try:\n",
        "    print('ERROR: Not connected to a TPU runtime!')\n",
        "    GPUs = GPUtil.getGPUs()\n",
        "    print('GPU count: ' + str(len(GPUs)))\n",
        "    gpu_info = !nvidia-smi\n",
        "    gpu_info = '\\n'.join(gpu_info)\n",
        "    if gpu_info.find('failed') >= 0:\n",
        "      print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "      print('and then re-execute this cell.')\n",
        "    else:\n",
        "      print(gpu_info)\n",
        "  except:\n",
        "    print('Using CPU')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.2.0\n",
            "Running on TPU  ['10.61.95.42:8470']\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.61.95.42:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.61.95.42:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StODOp9qm7As",
        "colab_type": "code",
        "outputId": "c21c0b68-470f-4b29-b0e7-2d49f6869921",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import gym\n",
        "import threading\n",
        "import math\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "import multiprocessing\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from gym.wrappers import Monitor\n",
        "from tensorflow import keras\n",
        "from os import path\n",
        "from time import sleep\n",
        "from tqdm.notebook import tqdm\n",
        "from IPython.display import HTML\n",
        "from IPython import display as ipythondisplay\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Display cmd_param=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1001'] cmd=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1001'] oserror=None return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvT2J4Oa6AsX",
        "colab_type": "code",
        "outputId": "876f811f-ba73-4694-8876-98e29dfbb419",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('using tensorflow', tf.__version__)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using tensorflow 2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR4rdPq23olN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_video(id='video', base='.'):\n",
        "  mp4list = glob.glob(f'{path.join(base, id)}/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 200px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")\n",
        "\n",
        "def wrap_env(env, id='video', base='.'):\n",
        "  wrapped_env = Monitor(env, path.join(base, id), force=True)\n",
        "  return wrapped_env"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG-mqsx41fhc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PipelineArgs():\n",
        "  def __init__(self,\n",
        "               game_name='Acrobot-v1',\n",
        "               mode='train',\n",
        "               max_eps=100,\n",
        "               update_freq=20,\n",
        "               gamma=0.99,\n",
        "               model_path='.',\n",
        "               load_model=False,\n",
        "               max_testing_steps=1000,\n",
        "               round_cnt=10,\n",
        "               lr=0.001):\n",
        "    self.game_name = game_name\n",
        "    self.mode = mode\n",
        "    self.gamma = gamma\n",
        "    self.update_freq = update_freq\n",
        "    self.lr = lr\n",
        "    self.max_eps = max_eps\n",
        "    self.load_model = load_model\n",
        "    self.model_path = model_path\n",
        "    self.max_testing_steps = max_testing_steps\n",
        "    self.round_cnt = round_cnt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bz8PHZKXb-db",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class History():\n",
        "  def __init__(self, args):\n",
        "    self.history = pd.DataFrame(columns=['reward', 'loss'])\n",
        "    self.args = args\n",
        "  \n",
        "  def record(self, reward, loss):\n",
        "    self.history.append([reward, loss], ignore_index=True)\n",
        "\n",
        "  def visualize(self):\n",
        "    plt.figure()\n",
        "    plt.plot(self.history['loss'])\n",
        "    plt.show()\n",
        "\n",
        "  def save(self):\n",
        "    self.history.to_csv(path.join(self.args.model_path, 'history.csv'))\n",
        "  \n",
        "  def load(self):\n",
        "    if path.exists(\n",
        "        path.join(\n",
        "            self.args.model_path, 'history.csv')) and self.args.load_model:\n",
        "      self.history = pd.DataFrame()\n",
        "      self.history.read_csv(path.join(self.args.model_path, 'history.csv'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "to5WdjMOBij4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Memory():\n",
        "  def __init__(self):\n",
        "    self.states = []\n",
        "    self.actions = []\n",
        "    self.rewards = []\n",
        "  \n",
        "  def store(self, state, action, reward):\n",
        "    self.states.append(state)\n",
        "    self.actions.append(action)\n",
        "    self.rewards.append(reward)\n",
        "\n",
        "  def clear(self):\n",
        "    self.states = []\n",
        "    self.actions = []\n",
        "    self.rewards = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPNOZzhineIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Worker(threading.Thread):\n",
        "  # The cumulative episode played\n",
        "  global_eps = 0\n",
        "  best_score = 0\n",
        "  lock = threading.Lock()\n",
        "\n",
        "  def __init__(self,\n",
        "               args,\n",
        "               action_size,\n",
        "               state_size,\n",
        "               global_model,\n",
        "               opt,\n",
        "               pbar,\n",
        "               logger):\n",
        "    super(Worker, self).__init__()\n",
        "    self.args = args\n",
        "    self.game_name = self.args.game_name\n",
        "    self.env = gym.make(self.game_name)\n",
        "    self.action_size = action_size\n",
        "    self.state_size = state_size\n",
        "    self.local_model = ActorCriticModel(self.state_size, self.action_size)\n",
        "    self.eps_loss = 0\n",
        "    self.opt = opt\n",
        "    self.global_model = global_model\n",
        "    self.pbar = pbar\n",
        "    self.logger = logger\n",
        "\n",
        "  def compute_loss(self, done, new_state, memory):\n",
        "    if done:\n",
        "      reward_sum = 0\n",
        "    else:\n",
        "      reward_sum = self.local_model(\n",
        "          tf.convert_to_tensor(\n",
        "              new_state[None, :],\n",
        "              dtype=tf.float32))[-1].numpy()[0]\n",
        "    discounted_rewards = []\n",
        "    for reward in memory.rewards[::-1]:\n",
        "      reward_sum = reward + self.args.gamma * reward_sum\n",
        "      discounted_rewards.append(reward_sum)\n",
        "    discounted_rewards.reverse()\n",
        "    past_states = np.array(memory.states)\n",
        "    logits, values = self.local_model(\n",
        "        tf.convert_to_tensor(past_states, dtype=tf.float32))\n",
        "    advantage = tf.convert_to_tensor(\n",
        "        np.array(discounted_rewards)[:, None], dtype=tf.float32) - values\n",
        "    # Calculate the loss for value function which mean how off is our\n",
        "    # predicted value from the true value estimated from the discounted\n",
        "    # reward.\n",
        "    value_loss = advantage ** 2\n",
        "    # Calculate the policy loss\n",
        "    policy = tf.nn.softmax(logits)\n",
        "    entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
        "        labels=policy, logits=logits)\n",
        "    policy_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "        labels=memory.actions, logits=logits)\n",
        "    policy_loss *= tf.stop_gradient(advantage)\n",
        "    policy_loss -= 0.01 * entropy\n",
        "    # Combine the value and policy loss to be a single trainable\n",
        "    total_loss = tf.reduce_mean((0.5 * value_loss + policy_loss))\n",
        "    return total_loss\n",
        "\n",
        "  def compute_and_apply_gradient(self, done, new_state, mem):\n",
        "    with tf.GradientTape() as tape:\n",
        "      total_loss = self.compute_loss(done, new_state, mem)\n",
        "    self.eps_loss += total_loss\n",
        "    grads = tape.gradient(\n",
        "        total_loss, self.local_model.trainable_weights)\n",
        "    self.opt.apply_gradients(zip(\n",
        "        grads, self.global_model.trainable_weights))\n",
        "    self.local_model.set_weights(self.global_model.get_weights())\n",
        "    return total_loss\n",
        "\n",
        "  def run(self):\n",
        "    # Prepare variables\n",
        "    mem = Memory()\n",
        "    total_steps = 1\n",
        "    # Check the maximum episode of learning is reached\n",
        "    while Worker.global_eps < self.args.max_eps:\n",
        "      current_state = self.env.reset()\n",
        "      mem.clear()\n",
        "      done = False\n",
        "      ep_reward = 0\n",
        "      self.eps_loss = 0\n",
        "      time_count = 0\n",
        "      ep_steps = 0\n",
        "      # Check if the game is over\n",
        "      while not done:\n",
        "        # Get the policy and play the game\n",
        "        logits, _ = self.local_model(\n",
        "            tf.convert_to_tensor(np.array([current_state]), dtype=tf.float32))\n",
        "        probs = tf.nn.softmax(logits)\n",
        "        action = np.random.choice(self.action_size, p=probs.numpy()[0])\n",
        "        new_state, reward, done, info = self.env.step(action)\n",
        "        if reward == 0:\n",
        "          reward = -0.01\n",
        "        if done:\n",
        "          reward = -1.0\n",
        "        ep_reward += reward\n",
        "        mem.store(current_state, action, reward)\n",
        "        # If the explore time limit has been reached or\n",
        "        # the game is over, then update the models\n",
        "        if time_count >= self.args.update_freq or done:\n",
        "          loss = self.compute_and_apply_gradient(done, new_state, mem)\n",
        "          mem.clear()\n",
        "          time_count = 0\n",
        "          if done:\n",
        "            with Worker.lock:\n",
        "              self.logger.record(ep_reward, loss)\n",
        "              if Worker.global_eps == 0 or ep_reward > Worker.best_score:\n",
        "                self.global_model.save_weights(\n",
        "                    path.join(self.args.model_path, 'best.h5'))\n",
        "                Worker.best_score = ep_reward\n",
        "              self.global_model.save_weights(\n",
        "                  path.join(self.args.model_path, 'backup.h5'))\n",
        "              Worker.global_eps += 1\n",
        "              self.pbar.set_description(\n",
        "                  f'step: {ep_steps}, reward {round(ep_reward, 2)}/{round(Worker.best_score, 2)}')\n",
        "              self.pbar.update(1)\n",
        "        ep_steps += 1\n",
        "        time_count += 1\n",
        "        current_state = new_state\n",
        "        total_steps += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnSC4zC4nt9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ActorCriticModel(keras.Model):\n",
        "  def __init__(self, state_size, action_size):\n",
        "    super(ActorCriticModel, self).__init__()\n",
        "    self.state_size = state_size\n",
        "    self.action_size = action_size\n",
        "    self.conv_0 = keras.layers.Conv2D(\n",
        "        filters=32,\n",
        "        strides=(2, 2),\n",
        "        kernel_size=4,\n",
        "        activation='relu',\n",
        "        padding='same',\n",
        "        kernel_initializer='glorot_uniform',\n",
        "        input_shape=(160, 160, 3))\n",
        "    self.conv_1 = keras.layers.Conv2D(\n",
        "        filters=32,\n",
        "        activation='relu',\n",
        "        strides=(2, 2),\n",
        "        padding='same',\n",
        "        kernel_initializer='glorot_uniform',\n",
        "        kernel_size=4)\n",
        "    self.conv_2 = keras.layers.Conv2D(\n",
        "        filters=32,\n",
        "        activation='relu',\n",
        "        strides=(2, 2),\n",
        "        padding='same',\n",
        "        kernel_initializer='glorot_uniform',\n",
        "        kernel_size=4)\n",
        "    self.conv_3 = keras.layers.Conv2D(\n",
        "        filters=32,\n",
        "        activation='relu',\n",
        "        strides=(2, 2),\n",
        "        padding='same',\n",
        "        kernel_initializer='glorot_uniform',\n",
        "        kernel_size=4)\n",
        "    self.avg_pooling = tf.keras.layers.AveragePooling2D(pool_size=(2, 2))\n",
        "    self.flatten = keras.layers.Flatten()\n",
        "    self.policy_dense_0 = keras.layers.Dense(\n",
        "        64, kernel_initializer='glorot_uniform', activation='relu')\n",
        "    self.policy_logits = keras.layers.Dense(self.action_size, activation='relu')\n",
        "    self.value_dense = keras.layers.Dense(\n",
        "        64, kernel_initializer='glorot_uniform', activation='relu')\n",
        "    self.value = keras.layers.Dense(1)\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    x = tf.image.resize(inputs, (160, 160))\n",
        "    x = self.conv_0(x)\n",
        "    x = self.conv_1(x)\n",
        "    x = self.conv_2(x)\n",
        "    x = self.conv_3(x)\n",
        "    x = self.avg_pooling(x)\n",
        "    x = self.flatten(x)\n",
        "    p = self.policy_dense_0(x)\n",
        "    logits = self.policy_logits(p)\n",
        "    v = self.value_dense(x)\n",
        "    values = self.value(v)\n",
        "    return logits, values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtTON1xmoJCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BaselineModel():\n",
        "  def __init__(self):\n",
        "    print('not implemented')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVDqVpOqn_e0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MasterAgent():\n",
        "  def __init__(self, args):\n",
        "    self.args = args\n",
        "    self.game_name = self.args.game_name\n",
        "    env = gym.make(self.game_name)\n",
        "    self.action_size = env.action_space.n\n",
        "    self.history = History(self.args)\n",
        "    self.state_size = env.observation_space.shape[0]\n",
        "    self.opt = tf.optimizers.Adam(self.args.lr)\n",
        "    print('state_size: ', env.observation_space.shape)\n",
        "    print('action_size: ', self.action_size)\n",
        "    self.global_model = ActorCriticModel(self.state_size, self.action_size)\n",
        "    self.global_model(\n",
        "      tf.convert_to_tensor(\n",
        "      np.random.random((5, 210, 160, 3)),\n",
        "      dtype=tf.float32))\n",
        "    if path.exists(\n",
        "        path.join(self.args.model_path, 'backup.h5')) and self.args.load_model:\n",
        "      self.global_model.load_weights(\n",
        "          path.join(self.args.model_path, 'backup.h5'))\n",
        "  \n",
        "  def train_sync_round(self):\n",
        "    pbar = tqdm(total=self.args.max_eps)\n",
        "    worker = Worker(self.args, self.action_size, self.state_size,\n",
        "                    self.global_model, self.opt, pbar, self.history)\n",
        "    worker.run()\n",
        "    pbar.close()\n",
        "\n",
        "  def train_sync(self):\n",
        "    for r in range(self.args.round_cnt):\n",
        "      Worker.global_eps = 0\n",
        "      self.train_sync_round()\n",
        "      self.eval(f'test at round {str(r)}')\n",
        "      self.history.visualize()\n",
        "    print('all done')\n",
        "  \n",
        "  def train_async_round(self):\n",
        "    pbar = tqdm(total=self.args.max_eps + multiprocessing.cpu_count())\n",
        "    Worker.global_eps = 0;\n",
        "    workers = [\n",
        "      Worker(self.args, self.action_size, self.state_size,\n",
        "             self.global_model, self.opt, pbar, self.history)\n",
        "      for i in range(multiprocessing.cpu_count())\n",
        "    ]\n",
        "    worker_pbar = tqdm(total=len(workers))\n",
        "    worker_pbar.set_description(f'starting {len(workers)} workers')\n",
        "    for i, worker in enumerate(workers):\n",
        "      worker.start()\n",
        "      worker_pbar.update(1)\n",
        "    worker_pbar.close()\n",
        "    [w.join() for w in workers]\n",
        "    pbar.close()\n",
        "  \n",
        "  def train_async(self):\n",
        "    for r in range(self.args.round_cnt):\n",
        "      Worker.global_eps = 0\n",
        "      self.train_async_round()\n",
        "      self.eval(f'test at round {str(r)}')\n",
        "      self.history.visualize()\n",
        "    print('all done')\n",
        "\n",
        "  def eval(self, id):\n",
        "    self.play(load=False, id=id, base=self.args.model_path)\n",
        "  \n",
        "  def play(self, load=True, id='video', base='./'):\n",
        "    env = wrap_env(gym.make(self.args.game_name), id=id, base=base)\n",
        "    state = env.reset()\n",
        "    model_snapshot = self.global_model\n",
        "    if load and path.exists(\n",
        "        path.join(self.args.model_path, 'best.h5')):\n",
        "      print('load pre-trained model')\n",
        "      model_snapshot.load_weights(\n",
        "          path.join(self.args.model_path, 'best.h5'))\n",
        "    done = False\n",
        "    trial_steps = 0\n",
        "    pbar = tqdm(total=self.args.max_testing_steps)\n",
        "    cumulative_reward = 0\n",
        "    while (not done) and (trial_steps < self.args.max_testing_steps):\n",
        "      state_input = tf.convert_to_tensor(state[None, :], dtype=tf.float32)\n",
        "      logit, _ = model_snapshot(state_input)\n",
        "      policy = tf.nn.softmax(logit)\n",
        "      action = np.argmax(policy)\n",
        "      state, reward, done, _ = env.step(action)\n",
        "      cumulative_reward += reward\n",
        "      trial_steps += 1\n",
        "      pbar.update(1)\n",
        "    print(f'The final reward for this trial is {cumulative_reward}')\n",
        "    pbar.close()\n",
        "    env.close()\n",
        "    show_video(id=id, base=base)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yy5tn0pA2-tB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gym_sanity_check(args):\n",
        "  print('starting gym environment sanity check')\n",
        "  env = wrap_env(gym.make(args.game_name))\n",
        "  inital_observation = env.reset()\n",
        "  sample_action = env.action_space.sample()\n",
        "  print('observation shape: ', np.array(inital_observation).shape)\n",
        "  print('sample action: ', sample_action)\n",
        "  for _ in range(20):\n",
        "    observation = env.reset()\n",
        "    done = False\n",
        "    while not done:\n",
        "        action = env.action_space.sample()\n",
        "        observation, _, done, _ = env.step(action)\n",
        "  env.close()\n",
        "  show_video()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_4XwuN1oFkz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def entry_point(args):\n",
        "  if args.mode == 'sanity':\n",
        "    gym_sanity_check(args)\n",
        "  if args.mode == 'play':\n",
        "    master = MasterAgent(args)\n",
        "    master.play()\n",
        "  if args.mode == 'train_sync':\n",
        "    master = MasterAgent(args)\n",
        "    master.train_sync()\n",
        "  if args.mode == 'train_async':\n",
        "    master = MasterAgent(args)\n",
        "    master.train_async()\n",
        "  print('Hello World')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_oklLOXofGu",
        "colab_type": "code",
        "outputId": "bd30c9dc-9fd0-4ca6-97f8-81b520f3fd6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132,
          "referenced_widgets": [
            "44f2cb9739db4305ab59e8b7991e8cc3",
            "ac353d2b5b324220bfd28b92e825f666",
            "4a4b2a5354e24fdaaf1eee6eb953034f",
            "5a7dff722ede43b8b5379a22216c7a0f",
            "95c86602637b4a2b9a69bbb5785278c6",
            "158e0a7bf5eb4d14a06b10c0abb56c94",
            "572bdd2c7e714453a277aed1e4e2c546",
            "a4ff58fcaf61472b98238493ca1b31c4",
            "a623ffdf953246f59ee1a12bc14f2055",
            "053c11c11b594d73b838345a59537871",
            "dbf6225c053941d9af431451e3c5b711",
            "0029fff1e94c4354bbf2572e99e2bfa2",
            "cb445b5843cb479f968818ef86309f52",
            "f25f94879a8343bb9cbaf2e8e2de5344",
            "dda6cf9ab89f4e298b729dd895e3d7d1",
            "e68295094cf64a6e8cbc4c37e09b2fa9"
          ]
        }
      },
      "source": [
        "entry_point(\n",
        "    PipelineArgs(\n",
        "        game_name='Breakout-v0',\n",
        "        update_freq=20,\n",
        "        max_eps=100,\n",
        "        model_path='/content/drive/My Drive/colab_storage',\n",
        "        max_testing_steps=1000,\n",
        "        load_model=False,\n",
        "        round_cnt=60,\n",
        "        mode='train_async'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "state_size:  (210, 160, 3)\n",
            "action_size:  4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44f2cb9739db4305ab59e8b7991e8cc3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a623ffdf953246f59ee1a12bc14f2055",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNDSeZ4Nune5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}